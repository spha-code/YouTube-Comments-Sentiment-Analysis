{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DutOA_mJ9zYD",
        "outputId": "87d0061e-9a9f-4214-d62b-465ab9c9fb1c"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow optuna xgboost imbalanced-learn lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Set up the MLflow tracking server locally\n",
        "- To CONTNUE RUN THIS COMMAND IN TERMINAL!\n",
        "- mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 127.0.0.1 --port 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vch7jvzg-O9C"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "# Set local MLflow tracking URI\n",
        "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aPGvuI7-Yu_",
        "outputId": "3dce621e-5886-4278-f010-b60ce2a8c98a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/home/user/Youtube-Comments-Sentiment-Analysis/mlruns/9', creation_time=1752940074016, experiment_id='9', last_update_time=1752940074016, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNoYRU5W-gdD",
        "outputId": "c3dca95b-f9f6-439d-d3b6-e5abb0f34fbe"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhAQ53ko-los",
        "outputId": "fa282c73-bb95-4d60-97f4-aa41001a3933"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(119455, 2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/sentiment_analysis.csv').dropna()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "9c1OkYCN-uUw",
        "outputId": "d19bf22e-f4fb-4dff-80a9-49e9629268a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-19 17:49:48,161] A new study created in memory with name: no-name-7fd7f905-07a7-4d71-818b-f091a3e0b778\n",
            "[I 2025-07-19 17:51:16,547] Trial 0 finished with value: 0.6502448620819555 and parameters: {'n_estimators': 117, 'learning_rate': 0.0005631896336654552, 'max_depth': 6}. Best is trial 0 with value: 0.6502448620819555.\n",
            "[I 2025-07-19 17:55:59,931] Trial 1 finished with value: 0.6723452346071742 and parameters: {'n_estimators': 206, 'learning_rate': 0.0012000039883343489, 'max_depth': 8}. Best is trial 1 with value: 0.6723452346071742.\n",
            "[I 2025-07-19 17:56:46,797] Trial 2 finished with value: 0.650161148549663 and parameters: {'n_estimators': 85, 'learning_rate': 0.00833237783418619, 'max_depth': 5}. Best is trial 1 with value: 0.6723452346071742.\n",
            "[I 2025-07-19 18:01:43,412] Trial 3 finished with value: 0.7007659788204763 and parameters: {'n_estimators': 170, 'learning_rate': 0.012938139837390802, 'max_depth': 9}. Best is trial 3 with value: 0.7007659788204763.\n",
            "[I 2025-07-19 18:07:11,365] Trial 4 finished with value: 0.7044075174751999 and parameters: {'n_estimators': 255, 'learning_rate': 0.01307592181526702, 'max_depth': 8}. Best is trial 4 with value: 0.7044075174751999.\n",
            "[I 2025-07-19 18:15:02,665] Trial 5 finished with value: 0.7208153698045289 and parameters: {'n_estimators': 254, 'learning_rate': 0.01835019659801443, 'max_depth': 10}. Best is trial 5 with value: 0.7208153698045289.\n",
            "[I 2025-07-19 18:16:05,882] Trial 6 finished with value: 0.703570382152275 and parameters: {'n_estimators': 287, 'learning_rate': 0.04546059035023366, 'max_depth': 3}. Best is trial 5 with value: 0.7208153698045289.\n",
            "[I 2025-07-19 18:18:38,347] Trial 7 finished with value: 0.6779121845046252 and parameters: {'n_estimators': 108, 'learning_rate': 0.004856108347272072, 'max_depth': 8}. Best is trial 5 with value: 0.7208153698045289.\n",
            "[I 2025-07-19 18:22:50,725] Trial 8 finished with value: 0.6764890544556528 and parameters: {'n_estimators': 139, 'learning_rate': 0.00014376838667938795, 'max_depth': 9}. Best is trial 5 with value: 0.7208153698045289.\n",
            "[I 2025-07-19 18:25:24,197] Trial 9 finished with value: 0.6711732451550794 and parameters: {'n_estimators': 149, 'learning_rate': 0.005433766581622621, 'max_depth': 7}. Best is trial 5 with value: 0.7208153698045289.\n",
            "[I 2025-07-19 18:29:56,738] Trial 10 finished with value: 0.7472269892428111 and parameters: {'n_estimators': 209, 'learning_rate': 0.07219152359234922, 'max_depth': 10}. Best is trial 10 with value: 0.7472269892428111.\n",
            "[I 2025-07-19 18:34:19,488] Trial 11 finished with value: 0.7555983424720606 and parameters: {'n_estimators': 222, 'learning_rate': 0.09904663287927504, 'max_depth': 10}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 18:38:35,651] Trial 12 finished with value: 0.7494453978485622 and parameters: {'n_estimators': 204, 'learning_rate': 0.08409650562168398, 'max_depth': 10}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 18:42:54,463] Trial 13 finished with value: 0.7523335147126533 and parameters: {'n_estimators': 210, 'learning_rate': 0.09211906092677381, 'max_depth': 10}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 18:44:12,197] Trial 14 finished with value: 0.6996358461345277 and parameters: {'n_estimators': 244, 'learning_rate': 0.03228035181571642, 'max_depth': 4}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 18:53:00,334] Trial 15 finished with value: 0.6810095851994475 and parameters: {'n_estimators': 293, 'learning_rate': 0.0017357837335208323, 'max_depth': 9}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 18:55:41,522] Trial 16 finished with value: 0.7107697459294295 and parameters: {'n_estimators': 180, 'learning_rate': 0.02888848994286437, 'max_depth': 7}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:00:13,682] Trial 17 finished with value: 0.754468209786112 and parameters: {'n_estimators': 234, 'learning_rate': 0.09226634074883128, 'max_depth': 10}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:03:15,419] Trial 18 finished with value: 0.6502448620819555 and parameters: {'n_estimators': 242, 'learning_rate': 0.00026074626776495757, 'max_depth': 6}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:08:33,936] Trial 19 finished with value: 0.7409066175547278 and parameters: {'n_estimators': 275, 'learning_rate': 0.04548458293983169, 'max_depth': 9}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:13:04,317] Trial 20 finished with value: 0.7111046000585994 and parameters: {'n_estimators': 233, 'learning_rate': 0.021727922564442854, 'max_depth': 8}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:17:25,488] Trial 21 finished with value: 0.7550960612783056 and parameters: {'n_estimators': 222, 'learning_rate': 0.09675954823488048, 'max_depth': 10}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:21:10,023] Trial 22 finished with value: 0.7507429575990959 and parameters: {'n_estimators': 180, 'learning_rate': 0.09651485244068243, 'max_depth': 10}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:25:50,932] Trial 23 finished with value: 0.735214097358838 and parameters: {'n_estimators': 227, 'learning_rate': 0.04488095969713878, 'max_depth': 9}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:31:38,089] Trial 24 finished with value: 0.7469339918797874 and parameters: {'n_estimators': 266, 'learning_rate': 0.057139296925511465, 'max_depth': 10}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:36:40,930] Trial 25 finished with value: 0.7249591896530074 and parameters: {'n_estimators': 222, 'learning_rate': 0.02929812794998822, 'max_depth': 9}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:40:35,541] Trial 26 finished with value: 0.7514126658574358 and parameters: {'n_estimators': 188, 'learning_rate': 0.09821331209586733, 'max_depth': 10}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:43:16,636] Trial 27 finished with value: 0.6634716001841697 and parameters: {'n_estimators': 155, 'learning_rate': 0.002834353649137922, 'max_depth': 7}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:47:30,001] Trial 28 finished with value: 0.7014356870788163 and parameters: {'n_estimators': 193, 'learning_rate': 0.013746242030373288, 'max_depth': 8}. Best is trial 11 with value: 0.7555983424720606.\n",
            "[I 2025-07-19 19:49:18,498] Trial 29 finished with value: 0.7293541500983634 and parameters: {'n_estimators': 266, 'learning_rate': 0.060680260581894185, 'max_depth': 5}. Best is trial 11 with value: 0.7555983424720606.\n",
            "\u001b[31m2025/07/19 19:54:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run XGBoost_SMOTE_TFIDF_Trigrams at: http://127.0.0.1:5000/#/experiments/9/runs/5bfae55746724d1691c32a614f3de225\n",
            "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/9\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "ngram_range = (1, 3)  # Trigram setting\n",
        "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
        "\n",
        "# Step 4: Train-test split before vectorization and resampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
        "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "\n",
        "# Step 6: Optuna objective function for XGBoost\n",
        "def objective_xgboost(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "\n",
        "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for XGBoost, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_xgboost, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
        "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
        "\n",
        "# Run the experiment for XGBoost\n",
        "run_optuna_experiment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7muRs3BED3o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
